# -*- coding: utf-8 -*-
"""IsoForestTrainer.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1cxqwdC381A4QK-HHVNTeayR9BHylWee0

Importing Dependencies
"""

import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
import matplotlib.gridspec as gridspec
from sklearn.ensemble import IsolationForest
from scipy.stats import skew
from sklearn.cluster import KMeans
from sklearn.preprocessing import StandardScaler
import pickle

"""Reading the Input file"""

data = pd.read_csv ('New_data_collection - Sheet1.csv')

data

"""Data exploration"""

data.describe()

plt.figure(figsize=(8,8))
plt.scatter(data['Current'], data['Power'])

plt.title('Current Vs Power')
plt.xlabel('Current')
plt.ylabel('Power')

extracted_columns = data[['Power']]

extracted_columns = extracted_columns.loc[(extracted_columns['Power'] < 100) | (extracted_columns['Power'] > 150)]

extracted_columns

extracted_columns_1 = data[['Energy']]

extracted_columns_1 = extracted_columns_1[extracted_columns_1['Energy'] <= 0.23]

extracted_columns_1 = extracted_columns_1[(extracted_columns_1['Energy'] < 0.01) | (extracted_columns_1['Energy'] > 0.17)]

extracted_columns_1

"""Adding anomalies data points to extracted_columns


"""

new_rows = [
    [535],
    [2070],
    [1600],
    [2006.4],
    [223],
    [6],
    [130],
    [600],
    [70],
    [730],
]

Anomalies_dp = pd.DataFrame(new_rows, columns=['Power'])

Anomalies_dp

new_df = pd.concat([extracted_columns, Anomalies_dp], ignore_index=True)

new_df

"""Adding anomalies data points to extracted_columns_1"""

new_rows_1 = [
    [0.3],
    [0.27],
    [0.4],
    [0.25],
    [0.28],
]

Anomalies_dp_1 = pd.DataFrame(new_rows_1, columns=['Energy'])

Anomalies_dp_1

new_df_1 = pd.concat([extracted_columns_1, Anomalies_dp_1], ignore_index=True)

new_df_1

Isolation_forest_model_0 =IsolationForest(n_estimators=100, max_samples='auto', contamination=0.002265518804,random_state=42)
Isolation_forest_model_1 =IsolationForest(n_estimators=70,  max_samples='auto', contamination=0.005037783375,random_state=42)

model_Isolation_forest_0 = Isolation_forest_model_0.fit(new_df_1)
model_Isolation_forest_1 = Isolation_forest_model_1.fit(new_df)  
 
x = Isolation_forest_model_0.predict(new_df_1) 
y = Isolation_forest_model_1.predict(new_df)  

with open('model_Isolation_forest_0.pkl', 'wb') as a:
    pickle.dump(model_Isolation_forest_0, a)

with open('model_Isolation_forest_1.pkl', 'wb') as b:
    pickle.dump(model_Isolation_forest_1, b)

x

index_1 = np.where(x == -1)

index_1

count_ones = np.count_nonzero(x == -1)

count_ones

y

index = np.where(y == -1)

index

count_ones_1 = np.count_nonzero(y == -1)

count_ones_1

Testing_data_1 = [
    [1.3],
    [0.8],
    [200],
    [1210],
    [535],
    [2010.2],
    [1450],
    [1230],
    [1100],
    [1023],
    [500],
    [600],
    [5],
    [148],
    [1221],
]

New_Testing_dp = pd.DataFrame(Testing_data_1, columns=['Power'])

New_Testing_dp

Testing_data_2 = [
    [0.31],
    [0.38],
    [0.22],
    [0.19],
    [0.18],
    [0.0],
    [0.23],
    [0.29],
    [0.26],
    [0.21],
    [0.20],
    [0.23],
    [0.24],
    [0.26],
    [0.33],
]

New_Testing_dp_1 = pd.DataFrame(Testing_data_2, columns=['Energy'])

New_Testing_dp_1

u = Isolation_forest_model_0.predict(New_Testing_dp_1) 
v = Isolation_forest_model_1.predict(New_Testing_dp)

u

v